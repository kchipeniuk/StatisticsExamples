{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6b12c5",
   "metadata": {},
   "source": [
    "<h2> Exercise 6 - Estimation of the Least Squares Predictor </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e640b",
   "metadata": {},
   "source": [
    "We will now estimate the optimal least squares predictor of a variable $y$ given a variable $x$ when $y$ is a linear function of $x$ plus an error term:\n",
    "\\begin{align}\n",
    "y = \\beta x + \\epsilon\n",
    "\\end{align}\n",
    "We will consider two possible residuals in this specification:\n",
    "\\begin{align}\n",
    "\\epsilon &\\sim \\text{N}(0,1)\\notag\\\\\n",
    "\\epsilon &\\sim e^x + u,\\ \\ u\\sim\\text{N}(0,1)\\notag\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a41f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06037151",
   "metadata": {},
   "source": [
    "For fun I'll draw the values of $x$ from a $\\chi_3^2$ distribution.  Generally speaking $\\chi_q^2$ distributions frequently arise as the asymptotic distributions of test statistics.  They have mean $q$ and variance $2q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f70dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0\n",
      "Variance: 6.0\n"
     ]
    }
   ],
   "source": [
    "d = Chisq(3);\n",
    "println(\"Mean: \", mean(d))\n",
    "println(\"Variance: \", var(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fae616",
   "metadata": {},
   "source": [
    "Next, we draw several values of $x$ and $\\epsilon$ and compute the corresponding values of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71267531",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000;\n",
    "beta = 2;\n",
    "x = rand(d,N);\n",
    "eps1 = rand(Normal(),N);\n",
    "eps2 = exp.(x) + rand(Normal(),N);\n",
    "y1 = beta*x+eps1;\n",
    "y2 = beta*x+eps2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36066238",
   "metadata": {},
   "source": [
    "Finally, we can compute the least squares predictor using the sample analogue of the first order condition solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54ebd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard normal errors: Estimated beta is 2.0023314822300837\n",
      "Nonlinear errors: Estimated beta is 107534.30805260035\n"
     ]
    }
   ],
   "source": [
    "betaHat1 = (x'*y1)/(x'*x);\n",
    "betaHat2 = (x'*y2)/(x'*x);\n",
    "println(\"Standard normal errors: Estimated beta is \", betaHat1)\n",
    "println(\"Nonlinear errors: Estimated beta is \", betaHat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42d3f2",
   "metadata": {},
   "source": [
    "When the residuals are independent of $x$, we get back the linear coefficient $\\beta$.  However, when they contain a nonlinear function of $x$ (and in this case a function which can drastically impact the value of $y$), the best linear predictor of $y$ is no longer $\\beta x$.  Rather, we get a very large coefficient which attempts to correct for the large impact of the $e^x$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb79f3",
   "metadata": {},
   "source": [
    "Repeating with a Cauchy distribution for $x$ or $\\epsilon$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60479e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cauchy distribution for x: Estimated beta is 1.9999671121058735\n",
      "Cauchy errors: Estimated beta is 2.0004583616675777\n"
     ]
    }
   ],
   "source": [
    "CauchyDraws = rand(Cauchy(),N);\n",
    "yCx = beta*CauchyDraws + eps1;\n",
    "yCeps = beta*x+CauchyDraws;\n",
    "betaHatCx = (CauchyDraws'*yCx)/(CauchyDraws'*CauchyDraws);\n",
    "betaHatCeps = (x'*yCeps)/(x'*x);\n",
    "println(\"Cauchy distribution for x: Estimated beta is \", betaHatCx)\n",
    "println(\"Cauchy errors: Estimated beta is \", betaHatCeps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6c303",
   "metadata": {},
   "source": [
    "Despite not satisfying the requirements of the law of large numbers (finite variance) in the population, the least squares predictor estimated in the finite sample still gives a close approximation to $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baea83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
