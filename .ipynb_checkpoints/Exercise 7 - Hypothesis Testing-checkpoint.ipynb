{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc95f13",
   "metadata": {},
   "source": [
    "<h2> Exercise 7 - Hypothesis Testing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd5dcc",
   "metadata": {},
   "source": [
    "We will now use the specifications in the previous example and consider the hypothesis $H_0:\\ \\beta_{\\text{LS}}>0$.  This time I'll use a $\\Gamma$ distribution for $x$, which is a distribution commonly used to model waiting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585beaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate with N(0,1) errors: -6.065083624640842\n",
      "Estimate with nonlinear errors: 5.789491750573473\n"
     ]
    }
   ],
   "source": [
    "using Distributions\n",
    "using PyPlot\n",
    "\n",
    "d = Gamma(0.5,0.05);\n",
    "N = 50;\n",
    "beta = -2.0;\n",
    "\n",
    "x = rand(d,N);\n",
    "eps1 = rand(Normal(),N);\n",
    "eps2 = exp.(x) + eps1;\n",
    "\n",
    "y1 = beta*x + eps1;\n",
    "y2 = beta*x + eps2;\n",
    "\n",
    "betaHat1 = (x'*y1)/(x'*x);\n",
    "betaHat2 = (x'*y2)/(x'*x);\n",
    "\n",
    "println(\"Estimate with N(0,1) errors: \", betaHat1)\n",
    "println(\"Estimate with nonlinear errors: \", betaHat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db4a85",
   "metadata": {},
   "source": [
    "We now need to estimate the variance of the asymptotic distribution,\n",
    "\\begin{align}\n",
    "\\sigma^2 = \\frac{\\mathbb{E}[x^2(y-\\beta_{\\text{LS}}x)^2]}{(\\mathbb{E}x^2)^2} \n",
    "\\end{align}\n",
    "using the sample analogue\n",
    "\\begin{align}\n",
    "\\widehat{\\sigma}^2 = \\frac{\\frac{1}{N}\\sum_{i=1}^N x_i^2(y_i-\\widehat{\\beta}_{\\text{LS}} x_i)^2}{\\left(\\frac{1}{N}\\sum_{i=1}^N x_i^2\\right)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "090e261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation with N(0,1) errors: 19.648985172567052\n",
      "Standard deviation with nonlinear errors: 19.46717849179151\n"
     ]
    }
   ],
   "source": [
    "sigHatSq1 = ((1.0/N)*(x.^2.0)'*((y1-betaHat1*x).^2.0))/(((1.0/N)*x'*x)^2.0)\n",
    "sigHatSq2 = ((1.0/N)*(x.^2.0)'*((y2-betaHat2*x).^2.0))/(((1.0/N)*x'*x)^2.0)\n",
    "\n",
    "sigHat1 = sqrt(sigHatSq1);\n",
    "sigHat2 = sqrt(sigHatSq2);\n",
    "\n",
    "println(\"Standard deviation with N(0,1) errors: \", sigHat1)\n",
    "println(\"Standard deviation with nonlinear errors: \", sigHat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ede76",
   "metadata": {},
   "source": [
    "In this case the asymptotic variances are quite similar, suggesting we'll have standard errors of comparable size for both residual types. We can now compute the test statistic $\\widehat{t}$ corresponding to our hypothesis as well as the standard errors themselves and corresponding $p$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4a3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic with N(0,1) errors: -2.182637791103147, Standard error: 2.7787861317912173\n",
      "Test statistic with nonlinear errors: 2.102918447159796, Standard error: 2.7530747844229366\n"
     ]
    }
   ],
   "source": [
    "tHat1 = betaHat1/(sigHat1/sqrt(N));\n",
    "tHat2 = betaHat2/(sigHat2/sqrt(N));\n",
    "se1 = sigHat1/sqrt(N);\n",
    "se2 = sigHat2/sqrt(N);\n",
    "\n",
    "println(\"Test statistic with N(0,1) errors: \", tHat1, \", Standard error: \", se1)\n",
    "println(\"Test statistic with nonlinear errors: \", tHat2, \", Standard error: \", se2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ddf3a",
   "metadata": {},
   "source": [
    "We can now compute the $p$ values as the likelihood of obtaining a value at least as large as $\\widehat{t}$ under the hypothesis that $\\beta_{\\text{LS}}$ is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb805ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value with N(0,1) errors: 0.985468752773136\n",
      "p value with nonlinear errors: 0.017736449495193374\n"
     ]
    }
   ],
   "source": [
    "p1 = 1.0-cdf(Normal(),tHat1)\n",
    "p2 = 1.0-cdf(Normal(),tHat2)\n",
    "\n",
    "println(\"p value with N(0,1) errors: \", p1)\n",
    "println(\"p value with nonlinear errors: \", p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b264b",
   "metadata": {},
   "source": [
    "We therefore fail to reject the null at significance level 0.05 with $\\text{N}(0,1)$ errors, reflecting the fact that the least squares predictor is just the linear coefficient -2 in this case, which is indeed negative.  In contrast, with nonlinear errors we reject the null at this significance level, reflecting the fact that the nonlinear component $e^x$ in the error term is strong enough to overcome the negative linear component when the least squares predictor is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e7280",
   "metadata": {},
   "source": [
    "For a further demonstration, let's consider how sample size and error distribution affect the case in which the error term is conditionally independent of $x$.  First, we'll do sample size, taking $\\beta$ to be a small positive number to increase the chance of a Type II error (false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7346abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing H0: beta<0\n",
      "\n",
      "Sample Size        coeff.     st.dev.     t        se       p\n",
      "-------------------------------------------------------------\n",
      "Small              0.24      1.20       1.52     0.16     0.06\n",
      "Large              0.30      1.23       4.64     0.06     0.00"
     ]
    }
   ],
   "source": [
    "beta = 0.3;\n",
    "Nsmall = 50;\n",
    "Nbig = 300;\n",
    "xsmall = rand(Normal(),Nsmall);\n",
    "xbig = rand(Normal(),Nbig);\n",
    "epssmall = rand(Normal(),Nsmall);\n",
    "epsbig = rand(Normal(),Nbig);\n",
    "ysmall = beta*xsmall + epssmall;\n",
    "ybig = beta*xbig + epsbig;\n",
    "\n",
    "betaHatsmall = (xsmall'*ysmall)/(xsmall'*xsmall);\n",
    "betaHatbig = (xbig'*ybig)/(xbig'*xbig);\n",
    "\n",
    "sigHatSqsmall = ((1.0/Nsmall)*(xsmall.^2.0)'*((ysmall-betaHatsmall*xsmall).^2.0))/(((1.0/Nsmall)*xsmall'*xsmall)^2.0)\n",
    "sigHatSqbig = ((1.0/Nbig)*(xbig.^2.0)'*((ybig-betaHatbig*xbig).^2.0))/(((1.0/Nbig)*xbig'*xbig)^2.0)\n",
    "\n",
    "sigHatsmall = sqrt(sigHatSqsmall);\n",
    "sigHatbig = sqrt(sigHatSqbig);\n",
    "\n",
    "tHatsmall = betaHatsmall/(sigHatsmall/sqrt(Nsmall));\n",
    "tHatbig = betaHatbig/(sigHatbig/sqrt(Nbig));\n",
    "sesmall = sigHatsmall/sqrt(Nsmall);\n",
    "sebig = sigHatbig/sqrt(Nbig);\n",
    "psmall = 1.0-cdf(Normal(),tHatsmall)\n",
    "pbig = 1.0-cdf(Normal(),tHatbig)\n",
    "\n",
    "println(\"Testing H0: beta<0\")\n",
    "println(\"\")\n",
    "println(\"Sample Size        coeff.     st.dev.     t        se       p\")\n",
    "println(\"-------------------------------------------------------------\")\n",
    "@printf \"Small              %.2f      %.2f       %.2f     %.2f     %.2f\\n\" betaHatsmall sigHatSqsmall tHatsmall sesmall psmall\n",
    "@printf \"Large              %.2f      %.2f       %.2f     %.2f     %.2f\" betaHatbig sigHatSqbig tHatbig sebig pbig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a350e8f",
   "metadata": {},
   "source": [
    "Running the above code multiple times will generally demonstrate that, with the sample sizes and coefficients chosen, you may end up with drastically different results in your test depending on your sample, although as expected the larger sample has a better chance of rejecting the null at the 0.05 significance level. \n",
    "\n",
    "Follow-up exercise: draw several samples, and estimate the probability of rejecting the null for each sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc57856",
   "metadata": {},
   "source": [
    "Finally, let's see how reducing the variance of the residuals affects the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f53d072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing H0: beta<0\n",
      "\n",
      "Sample Size        coeff.     st.dev.     t        se       p\n",
      "-------------------------------------------------------------\n",
      "Small              0.33      0.34       3.98     0.08     0.00\n",
      "Large              0.32      0.21       11.94     0.03     0.00"
     ]
    }
   ],
   "source": [
    "beta = 0.3;\n",
    "Nsmall = 50;\n",
    "Nbig = 300;\n",
    "xsmall = rand(Normal(),Nsmall);\n",
    "xbig = rand(Normal(),Nbig);\n",
    "epssmall = rand(Normal(0.0,0.5),Nsmall);\n",
    "epsbig = rand(Normal(0.0,0.5),Nbig);\n",
    "ysmall = beta*xsmall + epssmall;\n",
    "ybig = beta*xbig + epsbig;\n",
    "\n",
    "betaHatsmall = (xsmall'*ysmall)/(xsmall'*xsmall);\n",
    "betaHatbig = (xbig'*ybig)/(xbig'*xbig);\n",
    "\n",
    "sigHatSqsmall = ((1.0/Nsmall)*(xsmall.^2.0)'*((ysmall-betaHatsmall*xsmall).^2.0))/(((1.0/Nsmall)*xsmall'*xsmall)^2.0)\n",
    "sigHatSqbig = ((1.0/Nbig)*(xbig.^2.0)'*((ybig-betaHatbig*xbig).^2.0))/(((1.0/Nbig)*xbig'*xbig)^2.0)\n",
    "\n",
    "sigHatsmall = sqrt(sigHatSqsmall);\n",
    "sigHatbig = sqrt(sigHatSqbig);\n",
    "\n",
    "tHatsmall = betaHatsmall/(sigHatsmall/sqrt(Nsmall));\n",
    "tHatbig = betaHatbig/(sigHatbig/sqrt(Nbig));\n",
    "sesmall = sigHatsmall/sqrt(Nsmall);\n",
    "sebig = sigHatbig/sqrt(Nbig);\n",
    "psmall = 1.0-cdf(Normal(),tHatsmall)\n",
    "pbig = 1.0-cdf(Normal(),tHatbig)\n",
    "\n",
    "println(\"Testing H0: beta<0\")\n",
    "println(\"\")\n",
    "println(\"Sample Size        coeff.     st.dev.     t        se       p\")\n",
    "println(\"-------------------------------------------------------------\")\n",
    "@printf \"Small              %.2f      %.2f       %.2f     %.2f     %.2f\\n\" betaHatsmall sigHatSqsmall tHatsmall sesmall psmall\n",
    "@printf \"Large              %.2f      %.2f       %.2f     %.2f     %.2f\" betaHatbig sigHatSqbig tHatbig sebig pbig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bcd4b",
   "metadata": {},
   "source": [
    "Running the above code several times should demonstrate that we now have a very high chance of rejecting the null with either sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2527e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
